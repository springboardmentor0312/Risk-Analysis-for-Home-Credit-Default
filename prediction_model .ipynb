{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ece032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (1.2.7)\n",
      "Requirement already satisfied: dask[dataframe] in c:\\programdata\\anaconda3\\lib\\site-packages (2022.7.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (3.7.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.10.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (22.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2022.11.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (0.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost dask[dataframe]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a853a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_train.csv already exists.\n",
      "application_test.csv already exists.\n",
      "bureau.csv already exists.\n",
      "bureau_balance.csv already exists.\n",
      "credit_card_balance.csv already exists.\n",
      "installments_payments.csv already exists.\n",
      "previous_application.csv already exists.\n",
      "POS_CASH_balance.csv already exists.\n",
      "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
      "0      100002       1         Cash loans           M            N   \n",
      "1      100003       0         Cash loans           F            N   \n",
      "2      100004       0    Revolving loans           M            Y   \n",
      "3      100006       0         Cash loans           F            N   \n",
      "4      100007       0         Cash loans           M            N   \n",
      "\n",
      "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
      "0               Y             0          202500.0    406597.5      24700.5   \n",
      "1               N             0          270000.0   1293502.5      35698.5   \n",
      "2               Y             0           67500.0    135000.0       6750.0   \n",
      "3               Y             0          135000.0    312682.5      29686.5   \n",
      "4               Y             0          121500.0    513000.0      21865.5   \n",
      "\n",
      "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
      "0  ...                 0                0                0                0   \n",
      "1  ...                 0                0                0                0   \n",
      "2  ...                 0                0                0                0   \n",
      "3  ...                 0                0                0                0   \n",
      "4  ...                 0                0                0                0   \n",
      "\n",
      "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
      "0                        0.0                       0.0   \n",
      "1                        0.0                       0.0   \n",
      "2                        0.0                       0.0   \n",
      "3                        NaN                       NaN   \n",
      "4                        0.0                       0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
      "0                         0.0                        0.0   \n",
      "1                         0.0                        0.0   \n",
      "2                         0.0                        0.0   \n",
      "3                         NaN                        NaN   \n",
      "4                         0.0                        0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
      "0                        0.0                         1.0  \n",
      "1                        0.0                         0.0  \n",
      "2                        0.0                         0.0  \n",
      "3                        NaN                         NaN  \n",
      "4                        0.0                         0.0  \n",
      "\n",
      "[5 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gdown\n",
    "import requests\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Function to construct Google Drive direct download link\n",
    "def get_google_drive_url(file_id):\n",
    "    return f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Get file IDs from the .env file\n",
    "file_ids = {\n",
    "    \"application_train\": os.getenv(\"APPLICATION_TRAIN_ID\"),\n",
    "    \"application_test\": os.getenv(\"APPLICATION_TEST_ID\"),\n",
    "    \"bureau\": os.getenv(\"BUREAU_ID\"),\n",
    "    \"bureau_balance\": os.getenv(\"BUREAU_BALANCE_ID\"),\n",
    "    \"credit_card_balance\": os.getenv(\"CREDIT_CARD_BALANCE_ID\"),\n",
    "    \"installments_payments\": os.getenv(\"INSTALLMENTS_PAYMENTS_ID\"),\n",
    "    \"previous_application\": os.getenv(\"PREVIOUS_APPLICATION_ID\"),\n",
    "    \"POS_CASH_balance\": os.getenv(\"POS_CASH_BALANCE_ID\"),\n",
    "}\n",
    "\n",
    "# Construct direct download links\n",
    "google_drive_links = {key: get_google_drive_url(value) for key, value in file_ids.items()}\n",
    "\n",
    "# Function to download a file using gdown, only if not already downloaded\n",
    "def download_csv(file_url, output_path):\n",
    "    if not os.path.exists(output_path):  # Check if file already exists\n",
    "        print(f\"Downloading {output_path}...\")\n",
    "        try:\n",
    "            gdown.download(file_url, output_path, quiet=False)\n",
    "            print(f\"Downloaded {output_path}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading {file_url}: {e}\")\n",
    "    else:\n",
    "        print(f\"{output_path} already exists.\")\n",
    "\n",
    "# Define the output file paths\n",
    "output_paths = {\n",
    "    \"application_train\": \"application_train.csv\",\n",
    "    \"application_test\": \"application_test.csv\",\n",
    "    \"bureau\": \"bureau.csv\",\n",
    "    \"bureau_balance\": \"bureau_balance.csv\",\n",
    "    \"credit_card_balance\": \"credit_card_balance.csv\",\n",
    "    \"installments_payments\": \"installments_payments.csv\",\n",
    "    \"previous_application\": \"previous_application.csv\",\n",
    "    \"POS_CASH_balance\": \"POS_CASH_balance.csv\"\n",
    "}\n",
    "\n",
    "# Download the datasets\n",
    "for key, file_url in google_drive_links.items():\n",
    "    download_csv(file_url, output_paths[key])\n",
    "\n",
    "# Load datasets from local files\n",
    "try:\n",
    "    app_train = dd.read_csv(output_paths[\"application_train\"], on_bad_lines='skip')\n",
    "    app_test = dd.read_csv(output_paths[\"application_test\"], on_bad_lines='skip')\n",
    "    bureau = dd.read_csv(output_paths[\"bureau\"], on_bad_lines='skip')\n",
    "    bureau_balance = dd.read_csv(output_paths[\"bureau_balance\"], on_bad_lines='skip')\n",
    "    credit_card_balance = dd.read_csv(output_paths[\"credit_card_balance\"], on_bad_lines='skip')\n",
    "    installments_payments = dd.read_csv(output_paths[\"installments_payments\"], on_bad_lines='skip')\n",
    "    previous_application = dd.read_csv(output_paths[\"previous_application\"], on_bad_lines='skip')\n",
    "    POS_CASH_balance = dd.read_csv(output_paths[\"POS_CASH_balance\"], on_bad_lines='skip')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "\n",
    "# Example: Print the first few rows of the application_train dataset\n",
    "print(app_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaddf50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6391668\ttotal: 864ms\tremaining: 14m 23s\n",
      "100:\tlearn: 0.2360166\ttotal: 1m 10s\tremaining: 10m 30s\n",
      "200:\tlearn: 0.2214566\ttotal: 2m 17s\tremaining: 9m 4s\n",
      "300:\tlearn: 0.2099055\ttotal: 3m 26s\tremaining: 8m\n",
      "400:\tlearn: 0.1996075\ttotal: 4m 43s\tremaining: 7m 3s\n",
      "500:\tlearn: 0.1913675\ttotal: 5m 53s\tremaining: 5m 51s\n",
      "600:\tlearn: 0.1824031\ttotal: 7m 5s\tremaining: 4m 42s\n",
      "700:\tlearn: 0.1753951\ttotal: 8m 14s\tremaining: 3m 30s\n",
      "800:\tlearn: 0.1668866\ttotal: 9m 23s\tremaining: 2m 19s\n",
      "900:\tlearn: 0.1607977\ttotal: 11m 7s\tremaining: 1m 13s\n",
      "999:\tlearn: 0.1553940\ttotal: 12m 16s\tremaining: 0us\n",
      "('Defaulter', 346, 'Poor')\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to reduce memory usage\n",
    "def reduce_memory_usage(df):\n",
    "    # Check if the input is a Dask DataFrame\n",
    "    if isinstance(df, dd.DataFrame):\n",
    "        # Compute the Dask DataFrame to bring it into memory as a pandas DataFrame\n",
    "        df = df.compute()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:  # Exclude string columns\n",
    "            if pd.api.types.is_integer_dtype(col_type):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer', errors='ignore')\n",
    "            elif pd.api.types.is_float_dtype(col_type):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float', errors='ignore')\n",
    "    return df\n",
    "\n",
    "# Ensure app_train, app_test, and credit_card_balance are pandas DataFrames\n",
    "app_train = app_train.persist() if isinstance(app_train, dd.DataFrame) else app_train\n",
    "app_test = app_test.persist() if isinstance(app_test, dd.DataFrame) else app_test\n",
    "credit_card_balance = credit_card_balance.persist() if isinstance(credit_card_balance, dd.DataFrame) else credit_card_balance\n",
    "\n",
    "# Reduce memory usage for the datasets after ensuring they are pandas DataFrames\n",
    "app_train = reduce_memory_usage(app_train)\n",
    "app_test = reduce_memory_usage(app_test)\n",
    "credit_card_balance = reduce_memory_usage(credit_card_balance)\n",
    "\n",
    "# Columns from credit_card_balance for merging\n",
    "columns_to_merge = ['SK_ID_CURR', 'AMT_BALANCE', 'SK_DPD']\n",
    "credit_card_balance_selected = credit_card_balance[columns_to_merge]\n",
    "\n",
    "# Convert to Dask DataFrame with multiple partitions\n",
    "app_train_dd = dd.from_pandas(app_train, npartitions=10)\n",
    "credit_card_balance_dd = dd.from_pandas(credit_card_balance_selected, npartitions=10)\n",
    "app_test_dd = dd.from_pandas(app_test[['SK_ID_CURR']], npartitions=10)\n",
    "\n",
    "# Merging DataFrames on SK_ID_CURR using Dask\n",
    "merged_data_dd = dd.merge(app_train_dd, credit_card_balance_dd, on='SK_ID_CURR', how='left')\n",
    "merged_data_dd = dd.merge(merged_data_dd, app_test_dd, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Compute Dask DataFrame into a pandas DataFrame\n",
    "merged_data = merged_data_dd.compute()\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "merged_data['AMT_BALANCE'] = imputer.fit_transform(merged_data[['AMT_BALANCE']])\n",
    "merged_data['SK_DPD'] = SimpleImputer(strategy='median').fit_transform(merged_data[['SK_DPD']])\n",
    "\n",
    "# Binary categorical features to numeric\n",
    "binary_map = {'Y': 1, 'N': 0, 'M': 0, 'F': 1}\n",
    "merged_data['FLAG_OWN_CAR'] = merged_data['FLAG_OWN_CAR'].map(binary_map)\n",
    "merged_data['CODE_GENDER'] = merged_data['CODE_GENDER'].map(binary_map)\n",
    "\n",
    "# Label encode multi-category columns\n",
    "multi_category_columns = ['NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE', 'NAME_HOUSING_TYPE', 'NAME_CONTRACT_TYPE']\n",
    "label_encoders = {}\n",
    "for col in multi_category_columns:\n",
    "    le = LabelEncoder()\n",
    "    merged_data[col] = le.fit_transform(merged_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define the features for model input\n",
    "input_parameters = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_BALANCE', 'AMT_ANNUITY', 'SK_DPD', 'CNT_CHILDREN',\n",
    "    'FLAG_OWN_CAR', 'CODE_GENDER', 'DAYS_CREDIT', 'DAYS_DECISION', 'AMT_PAYMENT', \n",
    "    'AMT_INSTALMENT', 'AMT_APPLICATION'] + multi_category_columns\n",
    "\n",
    "# Available columns based on the data\n",
    "available_columns = [col for col in input_parameters if col in merged_data.columns]\n",
    "\n",
    "# List of numerical features for scaling\n",
    "numerical_features = [col for col in available_columns if col in [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_BALANCE', 'AMT_ANNUITY', 'SK_DPD', \n",
    "    'CNT_CHILDREN', 'DAYS_CREDIT', 'DAYS_DECISION', 'AMT_PAYMENT', 'AMT_INSTALMENT', 'AMT_APPLICATION']]\n",
    "\n",
    "# Split data into features and target\n",
    "training_data = merged_data[available_columns + ['TARGET']]\n",
    "X = training_data[available_columns]\n",
    "y = training_data['TARGET']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# CatBoost Classifier model\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=1000, \n",
    "    depth=10, \n",
    "    learning_rate=0.05, \n",
    "    loss_function='Logloss', \n",
    "    cat_features=[i for i, col in enumerate(X_train.columns) if X_train[col].dtype == 'object'],\n",
    "    verbose=100  # Adjust this as needed; set to 100 for less frequent logging\n",
    ")\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Save directory setup\n",
    "save_dir = 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Function to calculate credit score (unchanged)\n",
    "def calculate_credit_score(input_data):\n",
    "    sk_dpd = input_data.get('SK_DPD', 0) \n",
    "    amt_payment = input_data.get('AMT_PAYMENT', 0)\n",
    "    amt_installment = input_data.get('AMT_INSTALMENT', 0)\n",
    "    \n",
    "    if amt_installment > 0:\n",
    "        payment_ratio = min(amt_payment / amt_installment, 1)\n",
    "    else:\n",
    "        payment_ratio = 1 \n",
    "    payment_history_score = max(0, 1 - sk_dpd / 100) * 0.35\n",
    "    \n",
    "    amt_balance = input_data.get('AMT_BALANCE', 0)\n",
    "    amt_credit = input_data.get('AMT_CREDIT', 1) \n",
    "    credit_utilization_ratio = amt_balance / amt_credit\n",
    "    credit_utilization_score = max(0, 1 - credit_utilization_ratio) * 0.3\n",
    "    \n",
    "    days_credit = input_data.get('DAYS_CREDIT')\n",
    "    days_decision = input_data.get('DAYS_DECISION')\n",
    "    if days_credit is not None and days_decision is not None:\n",
    "        credit_history_length = abs(days_credit - days_decision)\n",
    "        length_of_credit_history_score = min(1, credit_history_length / 3650) * 0.15  \n",
    "    else:\n",
    "        length_of_credit_history_score = 0  \n",
    "    \n",
    "    name_contract_type = input_data.get('NAME_CONTRACT_TYPE', 'Unknown')\n",
    "    credit_type_score = 0.1 if name_contract_type in ['Cash loans', 'Revolving loans'] else 0\n",
    "    credit_mix_score = credit_type_score * 0.1 \n",
    "    \n",
    "    amt_application = input_data.get('AMT_APPLICATION', 0)\n",
    "    new_credit_score = min(1, amt_application / 500000) * 0.1 \n",
    "    \n",
    "    total_credit_score = (payment_history_score + credit_utilization_score +\n",
    "                          length_of_credit_history_score + credit_mix_score + new_credit_score) * 850 \n",
    "    \n",
    "    return int(total_credit_score)\n",
    "\n",
    "# FICO range function (unchanged)\n",
    "def determine_fico_range(credit_score):\n",
    "    if credit_score >= 800:\n",
    "        return \"Exceptional\"\n",
    "    elif credit_score >= 740:\n",
    "        return \"Very Good\"\n",
    "    elif credit_score >= 670:\n",
    "        return \"Good\"\n",
    "    elif credit_score >= 580:\n",
    "        return \"Fair\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "    \n",
    "# Prediction function using CatBoost\n",
    "def predict_default(input_data):\n",
    "    input_data = {k: v for k, v in input_data.items() if k in available_columns}\n",
    "    \n",
    "    input_data['FLAG_OWN_CAR'] = binary_map.get(input_data.get('FLAG_OWN_CAR', 'N'), 0)\n",
    "    input_data['CODE_GENDER'] = binary_map.get(input_data.get('CODE_GENDER', 'M'), 0)\n",
    "\n",
    "    for col, le in label_encoders.items():\n",
    "        if col in input_data:\n",
    "            input_data[col] = le.transform([input_data[col]])[0]\n",
    "\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    input_df[numerical_features] = scaler.transform(input_df[numerical_features])\n",
    "\n",
    "    is_defaulter = catboost_model.predict(input_df)[0]\n",
    "\n",
    "    credit_score = calculate_credit_score(input_data)\n",
    "    fico_range = determine_fico_range(credit_score)\n",
    "\n",
    "    if fico_range in ['Poor', 'Fair']:\n",
    "        is_defaulter = 1 \n",
    "\n",
    "    return (\"Defaulter\" if is_defaulter else \"Non-Defaulter\"), credit_score, fico_range\n",
    "\n",
    "# Example for prediction\n",
    "input_example = {\n",
    "    'AMT_INCOME_TOTAL': 50000,\n",
    "    'AMT_CREDIT': 200000,\n",
    "    'AMT_BALANCE': 150000,\n",
    "    'AMT_ANNUITY': 15000,\n",
    "    'SK_DPD': 5,\n",
    "    'CNT_CHILDREN': 1,\n",
    "    'FLAG_OWN_CAR': 'Y',\n",
    "    'CODE_GENDER': 'M',\n",
    "    'NAME_FAMILY_STATUS': 'Married',\n",
    "    'NAME_INCOME_TYPE': 'Working',\n",
    "    'NAME_HOUSING_TYPE': 'House / apartment',\n",
    "    'NAME_CONTRACT_TYPE': 'Cash loans',\n",
    "    'DAYS_CREDIT': -1000,\n",
    "    'DAYS_DECISION': -500,\n",
    "    'AMT_PAYMENT': 5000,\n",
    "    'AMT_INSTALMENT': 4000,\n",
    "    'AMT_APPLICATION': 250000\n",
    "}\n",
    "\n",
    "result = predict_default(input_example)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa13d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_CONTRACT_TYPE.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(catboost_model, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\catboost_model_pipeline.pkl')\n",
    "joblib.dump(scaler, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\scaler.pkl')\n",
    "\n",
    "label_encoder_NAME_FAMILY_STATUS = LabelEncoder()\n",
    "label_encoder_NAME_FAMILY_STATUS.fit(merged_data['NAME_FAMILY_STATUS'])\n",
    "\n",
    "label_encoder_NAME_INCOME_TYPE = LabelEncoder()\n",
    "label_encoder_NAME_INCOME_TYPE.fit(merged_data['NAME_INCOME_TYPE'])\n",
    "\n",
    "label_encoder_NAME_HOUSING_TYPE = LabelEncoder()\n",
    "label_encoder_NAME_HOUSING_TYPE.fit(merged_data['NAME_HOUSING_TYPE'])\n",
    "\n",
    "label_encoder_NAME_CONTRACT_TYPE = LabelEncoder()\n",
    "label_encoder_NAME_CONTRACT_TYPE.fit(merged_data['NAME_CONTRACT_TYPE'])\n",
    "\n",
    "# Save each encoder\n",
    "joblib.dump(label_encoder_NAME_FAMILY_STATUS, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_FAMILY_STATUS.pkl')\n",
    "joblib.dump(label_encoder_NAME_INCOME_TYPE, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_INCOME_TYPE.pkl')\n",
    "joblib.dump(label_encoder_NAME_HOUSING_TYPE, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_HOUSING_TYPE.pkl')\n",
    "joblib.dump(label_encoder_NAME_CONTRACT_TYPE, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_CONTRACT_TYPE.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ee020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
